{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconstrained Optimization - Optimization Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numdifftools in c:\\users\\seungyun\\anaconda3\\lib\\site-packages (0.9.41)\n",
      "Requirement already satisfied: numpy>=1.9 in c:\\users\\seungyun\\anaconda3\\lib\\site-packages (from numdifftools) (1.24.4)\n",
      "Requirement already satisfied: scipy>=0.8 in c:\\users\\seungyun\\anaconda3\\lib\\site-packages (from numdifftools) (1.9.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\seungyun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\seungyun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\seungyun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\seungyun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\seungyun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\seungyun\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install numdifftools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numdifftools 사용 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = lambda x : 4*x[1]**3+x[0]**2-12*x[1]**2-36*x[1]+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nd.Hessian(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H(np.array([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nd.Gradient(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2., -48.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steepest Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(fun, x0, step_length, max_iter=1000, epsilon=1e-3):\n",
    "    \n",
    "    fun = fun\n",
    "    x = copy.copy(x0)\n",
    "    \n",
    "    grad = nd.Gradient(fun)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(max_iter):\n",
    "        gradx = grad(x)\n",
    "        x -= step_length*gradx\n",
    "        count += 1\n",
    "        if np.linalg.norm(gradx)<epsilon:\n",
    "            break\n",
    "    return x, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(fun, x0, max_iter=1000, epsilon=1e-3):\n",
    "    \n",
    "    fun = fun\n",
    "    x = copy.copy(x0)\n",
    "    \n",
    "    grad = nd.Gradient(fun)\n",
    "    hess = nd.Hessian(fun)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(max_iter):\n",
    "        gradx = grad(x)\n",
    "        hessx = hess(x)\n",
    "        hessx = np.linalg.inv(hessx)\n",
    "        x -= hessx.dot(gradx)\n",
    "        count += 1\n",
    "        if np.linalg.norm(gradx)<epsilon:\n",
    "            break\n",
    "    return x, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasi-Newton (BFGS) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(fun, x0, step_length, max_iter=1000, epsilon=1e-3):\n",
    "    \n",
    "    fun = fun\n",
    "    x = copy.copy(x0)\n",
    "    H = np.eye(len(x))\n",
    "    grad = nd.Gradient(fun)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(max_iter):\n",
    "        gradx = grad(x)\n",
    "        x_new = x-step_length*H.dot(gradx)\n",
    "        count+=1\n",
    "        if np.linalg.norm(gradx)<epsilon:\n",
    "            break\n",
    "        \n",
    "        new_gradx = grad(x_new)\n",
    "        s = x_new-x\n",
    "        y = new_gradx-gradx\n",
    "        rho = 1/s.dot(y)\n",
    "        \n",
    "        H_new = (np.eye(len(x))-rho*np.dot(s.reshape(-1,1),y.reshape(1,-1))).dot(H)\n",
    "        H_new = H_new.dot(np.eye(len(x))-rho*np.dot(y.reshape(-1,1),s.reshape(1,-1)))\n",
    "        H_new = H_new+rho*np.dot(s.reshape(-1,1), s.reshape(1,-1))\n",
    "        \n",
    "        x = x_new\n",
    "        H = H_new\n",
    "        \n",
    "    return x, count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4.82454778e-04, 3.00000000e+00]), 378)\n",
      "(array([4.64506517e-04, 3.00000000e+00]), 188)\n",
      "(array([4.65429436e-04, 3.00000000e+00]), 124)\n",
      "(array([4.51376850e-05, 2.99998237e+00]), 120)\n",
      "(array([3.58341675e-13, 1.56112507e+00]), 1000)\n",
      "(array([9.09159186e-15, 4.00184913e+00]), 1000)\n",
      "(array([ 4.04802017e-01, -1.10955157e+31]), 9)\n",
      "(array([ 4.18210200e-01, -2.95431744e+26]), 8)\n",
      "(array([ 3.70559624e-01, -1.80954158e+17]), 7)\n",
      "(array([ 4.09599983e-01, -3.79398461e+20]), 7)\n"
     ]
    }
   ],
   "source": [
    "for step_length in range(10):\n",
    "    print(gradient_descent(fun, np.array([1., 2.]), 0.01*(1+step_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4.23599087e-05, 2.99997670e+00]), 1000)\n",
      "(array([7.37418005e-05, 2.99997981e+00]), 470)\n",
      "(array([2.09734529e-04, 3.00001853e+00]), 277)\n",
      "(array([3.70717849e-05, 3.00002014e+00]), 249)\n",
      "(array([1.81133597e-05, 3.00001993e+00]), 212)\n",
      "(array([1.14672600e-05, 3.00002032e+00]), 183)\n",
      "(array([7.92261929e-06, 3.00002037e+00]), 161)\n",
      "(array([5.67831647e-06, 3.00001995e+00]), 144)\n",
      "(array([4.35909059e-06, 3.00002012e+00]), 130)\n",
      "(array([3.26325736e-06, 3.00001926e+00]), 119)\n",
      "(array([2.73241647e-06, 3.00002021e+00]), 109)\n",
      "(array([2.18479473e-06, 3.00001995e+00]), 101)\n",
      "(array([1.79628527e-06, 3.00002001e+00]), 94)\n",
      "(array([1.47060105e-06, 3.00001981e+00]), 88)\n",
      "(array([1.16007741e-06, 3.00001877e+00]), 83)\n",
      "(array([1.01494746e-06, 3.00001963e+00]), 78)\n",
      "(array([8.18534532e-07, 3.00001886e+00]), 74)\n",
      "(array([7.16543729e-07, 3.00001963e+00]), 70)\n",
      "(array([5.51948410e-07, 3.00001797e+00]), 67)\n",
      "(array([4.50865811e-07, 3.00001746e+00]), 64)\n"
     ]
    }
   ],
   "source": [
    "for step_length in range(20):\n",
    "    print(BFGS(fun, np.array([1.,2.]), 0.01*(1+step_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.55431223e-15, 3.00000000e+00]), 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newton_method(fun, np.array([1.,2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.53343056e-06, 3.00000021e+00]), 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BFGS(fun, np.array([1.,2.]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014624834060668945"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "newton_method(fun, np.array([1.,2.]))\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01903247833251953"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "BFGS(fun, np.array([1.,2.]), 1)\n",
    "end = time.time()\n",
    "end-start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
